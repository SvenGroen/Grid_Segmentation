 Start of SGE job 


Hostname
perception.cv.uni-osnabrueck.de
Job-ID:
560517
user:
sgroen

Start

PWD: 
/net/projects/scratch/summer/valid_until_31_January_2021/sgroen/Git_Repos/Grid_Segmentation
RUNNING:  code/train_mixed.py
Current Environemt:  torch
CONFIG FOR RUNNING:  /net/projects/scratch/summer/valid_until_31_January_2021/sgroen/Git_Repos/Grid_Segmentation/code/models/trained_models/Examples_Green/multiples/Deep+_mobile_bs2_startLR1e-02Sched_Step_20ID1/train_config.json
Your job 560530 ("log_Deep+_mobile_ep85") has been submitted
Loading config:  /net/projects/scratch/summer/valid_until_31_January_2021/sgroen/Git_Repos/Grid_Segmentation/code/models/trained_models/Examples_Green/multiples/Deep+_mobile_bs2_startLR1e-02Sched_Step_20ID1/train_config.json
Trying to load previous Checkpoint ...
=> Loading checkpoint at epoch 58
--- Learning parameters: ---
Device: cuda; Model: Deep+_mobile;
Learning rate: 0.01; Number of epochs: 100; Batch Size: 2
Loss criterion:  <function cross_entropy at 0x2b39bdd99bf8>
Applied Augmentation Transforms:  [RandomPerspective(p=0.5), ColorJitter(brightness=[0.5, 1.5], contrast=[0.5, 1.5], saturation=[0.5, 1.5], hue=None), RandomAffine(degrees=(-10, 10), scale=(1, 1.5)), RandomGrayscale(p=0.1), RandomGrayscale(p=0.1), RandomHorizontalFlip(p=0.7)]
Normalized by Imagenet_Values:  False
Model Deep+_mobile saved at: /net/projects/scratch/summer/valid_until_31_January_2021/sgroen/Git_Repos/Grid_Segmentation/code/models/trained_models/Examples_Green/multiples/Deep+_mobile_bs2_startLR1e-02Sched_Step_20ID1/Deep+_mobile_bs2_startLR1e-02Sched_Step_20ID1
----------------------------
>>>Start of Training<<<
=> Saving checkpoint at epoch 58

epoch: 58,	 loss: 175.1290194678004
=> Saving checkpoint at epoch 58

epoch: 59,	 loss: 176.84489509486593
=> Saving checkpoint at epoch 59

epoch: 60,	 loss: 175.4091877200408
=> Saving checkpoint at epoch 60

epoch: 61,	 loss: 174.16646219580434
=> Saving checkpoint at epoch 61

epoch: 62,	 loss: 175.60710263316287
=> Saving checkpoint at epoch 62

epoch: 63,	 loss: 174.59949666334433
=> Saving checkpoint at epoch 63

epoch: 64,	 loss: 174.32123208703706
=> Saving checkpoint at epoch 64

epoch: 65,	 loss: 174.0330870578764
=> Saving checkpoint at epoch 65

epoch: 66,	 loss: 173.85208979644813
=> Saving checkpoint at epoch 66

epoch: 67,	 loss: 174.33751279197168
=> Saving checkpoint at epoch 67

epoch: 68,	 loss: 175.25957373698475
=> Saving checkpoint at epoch 68

epoch: 69,	 loss: 175.2633049056749
=> Saving checkpoint at epoch 69

epoch: 70,	 loss: 175.194799332181
=> Saving checkpoint at epoch 70

epoch: 71,	 loss: 174.54944191896357
=> Saving checkpoint at epoch 71

epoch: 72,	 loss: 174.82256047672126
=> Saving checkpoint at epoch 72

epoch: 73,	 loss: 173.9187336555333
=> Saving checkpoint at epoch 73

epoch: 74,	 loss: 175.11231525294716
=> Saving checkpoint at epoch 74

epoch: 75,	 loss: 174.58850752859144
=> Saving checkpoint at epoch 75

epoch: 76,	 loss: 174.09284958126955
=> Saving checkpoint at epoch 76

epoch: 77,	 loss: 173.81984998931875
=> Saving checkpoint at epoch 77

epoch: 78,	 loss: 174.9866445379157
=> Saving checkpoint at epoch 78

epoch: 79,	 loss: 174.47210875351448
=> Saving checkpoint at epoch 79

epoch: 80,	 loss: 173.73966617282713
=> Saving checkpoint at epoch 80

epoch: 81,	 loss: 174.5054909097962
=> Saving checkpoint at epoch 81

epoch: 82,	 loss: 174.35925381293055
=> Saving checkpoint at epoch 82

epoch: 83,	 loss: 175.51684395590564
=> Saving checkpoint at epoch 83

epoch: 84,	 loss: 173.711086885829
>>>End of Training<<<
=> Saving checkpoint at epoch 84
End of Python Script
