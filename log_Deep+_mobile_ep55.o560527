 Start of SGE job 


Hostname
twilight.cv.uni-osnabrueck.de
Job-ID:
560527
user:
sgroen

Start

PWD: 
/net/projects/scratch/summer/valid_until_31_January_2021/sgroen/Git_Repos/Grid_Segmentation
RUNNING:  code/train_mixed.py
Current Environemt:  torch
CONFIG FOR RUNNING:  /net/projects/scratch/summer/valid_until_31_January_2021/sgroen/Git_Repos/Grid_Segmentation/code/models/trained_models/Examples_Green/multiples/Deep+_mobile_bs2_startLR1e-02Sched_Step_25ID2/train_config.json
Your job 560540 ("log_Deep+_mobile_ep83") has been submitted
Loading config:  /net/projects/scratch/summer/valid_until_31_January_2021/sgroen/Git_Repos/Grid_Segmentation/code/models/trained_models/Examples_Green/multiples/Deep+_mobile_bs2_startLR1e-02Sched_Step_25ID2/train_config.json
Trying to load previous Checkpoint ...
=> Loading checkpoint at epoch 55
--- Learning parameters: ---
Device: cuda; Model: Deep+_mobile;
Learning rate: 0.01; Number of epochs: 100; Batch Size: 2
Loss criterion:  <function cross_entropy at 0x2b7f4170bbf8>
Applied Augmentation Transforms:  [RandomPerspective(p=0.5), ColorJitter(brightness=[0.5, 1.5], contrast=[0.5, 1.5], saturation=[0.5, 1.5], hue=None), RandomAffine(degrees=(-10, 10), scale=(1, 1.5)), RandomGrayscale(p=0.1), RandomGrayscale(p=0.1), RandomHorizontalFlip(p=0.7)]
Normalized by Imagenet_Values:  False
Model Deep+_mobile saved at: /net/projects/scratch/summer/valid_until_31_January_2021/sgroen/Git_Repos/Grid_Segmentation/code/models/trained_models/Examples_Green/multiples/Deep+_mobile_bs2_startLR1e-02Sched_Step_25ID2/Deep+_mobile_bs2_startLR1e-02Sched_Step_25ID2
----------------------------
>>>Start of Training<<<
=> Saving checkpoint at epoch 55

epoch: 55,	 loss: 171.9212838751264
=> Saving checkpoint at epoch 55

epoch: 56,	 loss: 172.31199525442207
=> Saving checkpoint at epoch 56

epoch: 57,	 loss: 171.34683872840833
=> Saving checkpoint at epoch 57

epoch: 58,	 loss: 171.84089021896943
=> Saving checkpoint at epoch 58

epoch: 59,	 loss: 172.14590055990266
=> Saving checkpoint at epoch 59

epoch: 60,	 loss: 171.88993327633943
=> Saving checkpoint at epoch 60

epoch: 61,	 loss: 172.30064042803133
=> Saving checkpoint at epoch 61

epoch: 62,	 loss: 172.24530736773158
=> Saving checkpoint at epoch 62

epoch: 63,	 loss: 171.76214698597323
=> Saving checkpoint at epoch 63

epoch: 64,	 loss: 171.88247954539838
=> Saving checkpoint at epoch 64

epoch: 65,	 loss: 171.4557379106991
=> Saving checkpoint at epoch 65

epoch: 66,	 loss: 172.0714001233864
=> Saving checkpoint at epoch 66

epoch: 67,	 loss: 171.04236389376456
=> Saving checkpoint at epoch 67

epoch: 68,	 loss: 171.8628706371819
=> Saving checkpoint at epoch 68

epoch: 69,	 loss: 171.80374072797713
=> Saving checkpoint at epoch 69

epoch: 70,	 loss: 171.35164834730676
=> Saving checkpoint at epoch 70

epoch: 71,	 loss: 171.0470118510275
=> Saving checkpoint at epoch 71

epoch: 72,	 loss: 170.9140372161928
=> Saving checkpoint at epoch 72

epoch: 73,	 loss: 171.48455729079433
=> Saving checkpoint at epoch 73

epoch: 74,	 loss: 170.98927087636548
=> Saving checkpoint at epoch 74

epoch: 75,	 loss: 171.1069467949128
=> Saving checkpoint at epoch 75

epoch: 76,	 loss: 171.47175510702073
=> Saving checkpoint at epoch 76

epoch: 77,	 loss: 170.9564644874481
=> Saving checkpoint at epoch 77

epoch: 78,	 loss: 170.6229423948389
=> Saving checkpoint at epoch 78

epoch: 79,	 loss: 170.032400993412
=> Saving checkpoint at epoch 79

epoch: 80,	 loss: 171.27463997731684
=> Saving checkpoint at epoch 80

epoch: 81,	 loss: 171.78948662863695
=> Saving checkpoint at epoch 81

epoch: 82,	 loss: 170.28367473163235
>>>End of Training<<<
=> Saving checkpoint at epoch 82
End of Python Script
