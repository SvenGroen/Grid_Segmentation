 Start of SGE job 


Hostname
perception.cv.uni-osnabrueck.de
Job-ID:
560492
user:
sgroen

Start

PWD: 
/net/projects/scratch/summer/valid_until_31_January_2021/sgroen/Git_Repos/Grid_Segmentation
RUNNING:  code/train_mixed.py
Current Environemt:  torch
CONFIG FOR RUNNING:  /net/projects/scratch/summer/valid_until_31_January_2021/sgroen/Git_Repos/Grid_Segmentation/code/models/trained_models/Examples_Green/multiples/Deep+_mobile_bs2_startLR1e-02Sched_Step_20ID1/train_config.json
Your job 560506 ("log_Deep+_mobile_ep29") has been submitted
Loading config:  /net/projects/scratch/summer/valid_until_31_January_2021/sgroen/Git_Repos/Grid_Segmentation/code/models/trained_models/Examples_Green/multiples/Deep+_mobile_bs2_startLR1e-02Sched_Step_20ID1/train_config.json
Trying to load previous Checkpoint ...
=> No previous checkpoint found
--- Learning parameters: ---
Device: cuda; Model: Deep+_mobile;
Learning rate: 0.01; Number of epochs: 100; Batch Size: 2
Loss criterion:  <function cross_entropy at 0x2b8fd1758bf8>
Applied Augmentation Transforms:  [RandomPerspective(p=0.5), ColorJitter(brightness=[0.5, 1.5], contrast=[0.5, 1.5], saturation=[0.5, 1.5], hue=None), RandomAffine(degrees=(-10, 10), scale=(1, 1.5)), RandomGrayscale(p=0.1), RandomGrayscale(p=0.1), RandomHorizontalFlip(p=0.7)]
Normalized by Imagenet_Values:  False
Model Deep+_mobile saved at: /net/projects/scratch/summer/valid_until_31_January_2021/sgroen/Git_Repos/Grid_Segmentation/code/models/trained_models/Examples_Green/multiples/Deep+_mobile_bs2_startLR1e-02Sched_Step_20ID1/Deep+_mobile_bs2_startLR1e-02Sched_Step_20ID1
----------------------------
>>>Start of Training<<<
=> Saving checkpoint at epoch 0

epoch: 0,	 loss: 476.0564362388104
=> Saving checkpoint at epoch 0

epoch: 1,	 loss: 367.3353722379543
=> Saving checkpoint at epoch 1

epoch: 2,	 loss: 349.788869664073
=> Saving checkpoint at epoch 2

epoch: 3,	 loss: 349.17738582380116
=> Saving checkpoint at epoch 3

epoch: 4,	 loss: 353.98521487694234
=> Saving checkpoint at epoch 4

epoch: 5,	 loss: 322.18436518730596
=> Saving checkpoint at epoch 5

epoch: 6,	 loss: 306.57681683963165
=> Saving checkpoint at epoch 6

epoch: 7,	 loss: 296.13671870942926
=> Saving checkpoint at epoch 7

epoch: 8,	 loss: 309.55517738859635
=> Saving checkpoint at epoch 8

epoch: 9,	 loss: 285.8584617964225
=> Saving checkpoint at epoch 9

epoch: 10,	 loss: 273.29779367521405
=> Saving checkpoint at epoch 10

epoch: 11,	 loss: 254.3101902862545
=> Saving checkpoint at epoch 11

epoch: 12,	 loss: 264.4892635192955
=> Saving checkpoint at epoch 12

epoch: 13,	 loss: 256.8841470936313
=> Saving checkpoint at epoch 13

epoch: 14,	 loss: 242.90410092967795
=> Saving checkpoint at epoch 14

epoch: 15,	 loss: 234.53526804613648
=> Saving checkpoint at epoch 15

epoch: 16,	 loss: 262.4531457386911
=> Saving checkpoint at epoch 16

epoch: 17,	 loss: 233.12062640261138
=> Saving checkpoint at epoch 17

epoch: 18,	 loss: 220.8202226688154
=> Saving checkpoint at epoch 18

epoch: 19,	 loss: 212.66456350655062
=> Saving checkpoint at epoch 19

epoch: 20,	 loss: 238.48462604917586
=> Saving checkpoint at epoch 20

epoch: 21,	 loss: 215.27190799778327
=> Saving checkpoint at epoch 21

epoch: 22,	 loss: 205.11163376132026
=> Saving checkpoint at epoch 22

epoch: 23,	 loss: 199.006806548452
=> Saving checkpoint at epoch 23

epoch: 24,	 loss: 196.37780012493022
=> Saving checkpoint at epoch 24

epoch: 25,	 loss: 193.54748621978797
=> Saving checkpoint at epoch 25

epoch: 26,	 loss: 189.81494762771763
=> Saving checkpoint at epoch 26

epoch: 27,	 loss: 190.22090914426371
=> Saving checkpoint at epoch 27

epoch: 28,	 loss: 186.57366351783276
>>>End of Training<<<
=> Saving checkpoint at epoch 28
End of Python Script
